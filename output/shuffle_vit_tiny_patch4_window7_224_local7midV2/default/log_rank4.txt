[2021-06-24 16:08:17 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 346): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /dockerdata/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 8
  PIN_MEMORY: true
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 4
MODEL:
  DROP_PATH_RATE: 0.1
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: shuffle_vit_tiny_patch4_window7_224_local7midV2
  NUM_CLASSES: 1000
  RESUME: ''
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: shuffle
OUTPUT: output/shuffle_vit_tiny_patch4_window7_224_local7midV2/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_LR: 0.001
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 1.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.0e-06
  WEIGHT_DECAY: 0.05

[2021-06-24 16:08:23 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 79): INFO Creating model:shuffle/shuffle_vit_tiny_patch4_window7_224_local7midV2
[2021-06-24 16:08:23 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 82): INFO ShuffleTransformer(
  (to_token): PatchEmbedding(
    (conv1): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (conv2): Sequential(
      (0): Conv2d(32, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (conv3): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
  )
  (stage1): StageModule(
    (layers): ModuleList(
      (0): ModuleList(
        (0): Block(
          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (drop_path): Identity()
          (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Block(
          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (drop_path): Identity()
          (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (stage2): StageModule(
    (patch_partition): PatchMerging(
      input dim=96, out dim=192
      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (reduction): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (layers): ModuleList(
      (0): ModuleList(
        (0): Block(
          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Block(
          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (stage3): StageModule(
    (patch_partition): PatchMerging(
      input dim=192, out dim=384
      (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (reduction): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (layers): ModuleList(
      (0): ModuleList(
        (0): Block(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Block(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): ModuleList(
        (0): Block(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Block(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): ModuleList(
        (0): Block(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Block(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (stage4): StageModule(
    (patch_partition): PatchMerging(
      input dim=384, out dim=768
      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (reduction): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (layers): ModuleList(
      (0): ModuleList(
        (0): Block(
          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Block(
          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (head): Linear(in_features=768, out_features=1000, bias=True)
)
[2021-06-24 16:08:23 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 91): INFO number of params: 28532482
[2021-06-24 16:08:23 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 118): INFO no checkpoint found in output/shuffle_vit_tiny_patch4_window7_224_local7midV2/default, ignoring auto resume
[2021-06-24 16:08:23 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 131): INFO Start training
[2021-06-24 16:08:29 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][0/1251]	eta 2:07:15 lr 0.000001	time 6.1032 (6.1032)	loss 6.9806 (6.9806)	grad_norm 1.2066 (1.2066)	mem 22902MB
[2021-06-24 16:08:36 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][10/1251]	eta 0:23:29 lr 0.000001	time 0.6265 (1.1357)	loss 6.9685 (6.9624)	grad_norm 1.0951 (1.1666)	mem 22902MB
[2021-06-24 16:08:42 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][20/1251]	eta 0:18:18 lr 0.000002	time 0.6088 (0.8923)	loss 6.9515 (6.9530)	grad_norm 1.0630 (1.1539)	mem 22902MB
[2021-06-24 16:08:48 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][30/1251]	eta 0:16:23 lr 0.000002	time 0.6200 (0.8052)	loss 6.9631 (6.9489)	grad_norm 1.2382 (1.1399)	mem 22902MB
[2021-06-24 16:08:55 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][40/1251]	eta 0:15:21 lr 0.000003	time 0.6285 (0.7610)	loss 6.9494 (6.9499)	grad_norm 1.2037 (1.1341)	mem 22902MB
[2021-06-24 16:09:01 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][50/1251]	eta 0:14:41 lr 0.000003	time 0.6220 (0.7343)	loss 6.9450 (6.9477)	grad_norm 1.0783 (1.1328)	mem 22902MB
[2021-06-24 16:09:07 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][60/1251]	eta 0:14:12 lr 0.000003	time 0.6121 (0.7161)	loss 6.9078 (6.9459)	grad_norm 1.0974 (1.1279)	mem 22902MB
[2021-06-24 16:09:13 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][70/1251]	eta 0:13:50 lr 0.000004	time 0.6228 (0.7032)	loss 6.9259 (6.9442)	grad_norm 1.2107 (1.1253)	mem 22902MB
[2021-06-24 16:09:19 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][80/1251]	eta 0:13:31 lr 0.000004	time 0.6237 (0.6934)	loss 6.9255 (6.9421)	grad_norm 1.2607 (1.1231)	mem 22902MB
[2021-06-24 16:09:26 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][90/1251]	eta 0:13:16 lr 0.000005	time 0.6257 (0.6860)	loss 6.9339 (6.9403)	grad_norm 1.1419 (1.1182)	mem 22902MB
[2021-06-24 16:09:32 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][100/1251]	eta 0:13:02 lr 0.000005	time 0.6293 (0.6801)	loss 6.9339 (6.9386)	grad_norm 1.0335 (1.1124)	mem 22902MB
[2021-06-24 16:09:38 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][110/1251]	eta 0:12:50 lr 0.000005	time 0.6356 (0.6757)	loss 6.9231 (6.9370)	grad_norm 1.0520 (1.1073)	mem 22902MB
[2021-06-24 16:09:45 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][120/1251]	eta 0:12:40 lr 0.000006	time 0.6353 (0.6724)	loss 6.9092 (6.9353)	grad_norm 1.1260 (1.1031)	mem 22902MB
[2021-06-24 16:09:51 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][130/1251]	eta 0:12:30 lr 0.000006	time 0.6402 (0.6697)	loss 6.9342 (6.9339)	grad_norm 1.0772 (1.0981)	mem 22902MB
[2021-06-24 16:09:57 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][140/1251]	eta 0:12:20 lr 0.000007	time 0.6433 (0.6669)	loss 6.9032 (6.9327)	grad_norm 1.1073 (1.0955)	mem 22902MB
[2021-06-24 16:10:04 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][150/1251]	eta 0:12:11 lr 0.000007	time 0.6258 (0.6643)	loss 6.8907 (6.9305)	grad_norm 0.9874 (1.0931)	mem 22902MB
[2021-06-24 16:10:10 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][160/1251]	eta 0:12:02 lr 0.000007	time 0.6275 (0.6622)	loss 6.8980 (6.9292)	grad_norm 0.9758 (1.0912)	mem 22902MB
[2021-06-24 16:10:16 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][170/1251]	eta 0:11:54 lr 0.000008	time 0.6493 (0.6605)	loss 6.9013 (6.9275)	grad_norm 1.0088 (1.0884)	mem 22902MB
[2021-06-24 16:10:23 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][180/1251]	eta 0:11:45 lr 0.000008	time 0.6308 (0.6588)	loss 6.8633 (6.9259)	grad_norm 1.1013 (1.0879)	mem 22902MB
[2021-06-24 16:10:29 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][190/1251]	eta 0:11:37 lr 0.000009	time 0.6335 (0.6573)	loss 6.9177 (6.9250)	grad_norm 0.9863 (1.0856)	mem 22902MB
[2021-06-24 16:10:35 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][200/1251]	eta 0:11:29 lr 0.000009	time 0.6342 (0.6560)	loss 6.9096 (6.9236)	grad_norm 1.0658 (1.0847)	mem 22902MB
[2021-06-24 16:10:41 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 221): INFO Train: [0/300][210/1251]	eta 0:11:21 lr 0.000009	time 0.6264 (0.6547)	loss 6.8848 (6.9219)	grad_norm 1.0989 (1.0844)	mem 22902MB
[2021-06-24 16:11:47 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 346): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /dockerdata/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 8
  PIN_MEMORY: true
  ZIP_MODE: false
EVAL_MODE: true
LOCAL_RANK: 4
MODEL:
  DROP_PATH_RATE: 0.1
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: shuffle_vit_tiny_patch4_window7_224_local7midV2
  NUM_CLASSES: 1000
  RESUME: ../pretrained_models/shuffle_vit_tiny_patch4_window7_224_local7midV2_drop0.1_82.41/ckpt_epoch_298.pth
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: shuffle
OUTPUT: output/shuffle_vit_tiny_patch4_window7_224_local7midV2/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_LR: 0.001
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 1.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.0e-06
  WEIGHT_DECAY: 0.05

[2021-06-24 16:11:52 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 79): INFO Creating model:shuffle/shuffle_vit_tiny_patch4_window7_224_local7midV2
[2021-06-24 16:11:53 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 82): INFO ShuffleTransformer(
  (to_token): PatchEmbedding(
    (conv1): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (conv2): Sequential(
      (0): Conv2d(32, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (conv3): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
  )
  (stage1): StageModule(
    (layers): ModuleList(
      (0): ModuleList(
        (0): Block(
          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (drop_path): Identity()
          (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Block(
          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (drop_path): Identity()
          (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (stage2): StageModule(
    (patch_partition): PatchMerging(
      input dim=96, out dim=192
      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (reduction): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (layers): ModuleList(
      (0): ModuleList(
        (0): Block(
          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Block(
          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (stage3): StageModule(
    (patch_partition): PatchMerging(
      input dim=192, out dim=384
      (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (reduction): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (layers): ModuleList(
      (0): ModuleList(
        (0): Block(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Block(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): ModuleList(
        (0): Block(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Block(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): ModuleList(
        (0): Block(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Block(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (stage4): StageModule(
    (patch_partition): PatchMerging(
      input dim=384, out dim=768
      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (reduction): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (layers): ModuleList(
      (0): ModuleList(
        (0): Block(
          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Block(
          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): Attention(
            (to_qkv): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (local): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (drop_path): DropPath()
          (norm2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): Mlp(
            (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))
            (act): ReLU6()
            (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=True)
          )
          (norm3): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (head): Linear(in_features=768, out_features=1000, bias=True)
)
[2021-06-24 16:11:53 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 91): INFO number of params: 28532482
[2021-06-24 16:11:53 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 118): INFO no checkpoint found in output/shuffle_vit_tiny_patch4_window7_224_local7midV2/default, ignoring auto resume
[2021-06-24 16:11:53 shuffle_vit_tiny_patch4_window7_224_local7midV2] (utils.py 20): INFO ==============> Resuming form ../pretrained_models/shuffle_vit_tiny_patch4_window7_224_local7midV2_drop0.1_82.41/ckpt_epoch_298.pth....................
[2021-06-24 16:11:55 shuffle_vit_tiny_patch4_window7_224_local7midV2] (utils.py 27): INFO <All keys matched successfully>
[2021-06-24 16:11:59 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 268): INFO Test: [0/49]	Time 3.957 (3.957)	Loss 0.8707 (0.8707)	Acc@1 82.520 (82.520)	Acc@5 96.484 (96.484)	Mem 6534MB
[2021-06-24 16:12:02 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 268): INFO Test: [10/49]	Time 0.194 (0.557)	Loss 0.8575 (0.9168)	Acc@1 83.301 (82.049)	Acc@5 96.777 (96.085)	Mem 6534MB
[2021-06-24 16:12:04 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 268): INFO Test: [20/49]	Time 0.189 (0.386)	Loss 0.9214 (0.9143)	Acc@1 81.934 (82.250)	Acc@5 95.703 (96.033)	Mem 6534MB
[2021-06-24 16:12:06 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 268): INFO Test: [30/49]	Time 0.186 (0.328)	Loss 0.9107 (0.9195)	Acc@1 83.301 (82.211)	Acc@5 96.289 (95.987)	Mem 6534MB
[2021-06-24 16:12:08 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 268): INFO Test: [40/49]	Time 0.215 (0.298)	Loss 0.9360 (0.9175)	Acc@1 82.324 (82.262)	Acc@5 95.801 (95.979)	Mem 6534MB
[2021-06-24 16:12:10 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 274): INFO  * Acc@1 82.384 Acc@5 96.066
[2021-06-24 16:12:10 shuffle_vit_tiny_patch4_window7_224_local7midV2] (main.py 123): INFO Accuracy of the network on the 50000 test images: 82.4%
